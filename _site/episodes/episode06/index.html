<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<html>
<head>
<meta charset="utf-8">


<title>Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc &mdash; Head in the Clouds</title>
<meta name="description" content="5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc



Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum.

Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.”

The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors.

Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands.

The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal.

To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html

I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown:

wget https://headintheclouds.site/extras/ep6/credential_report.csv


Let’s take a look at the file:

cat credential_report.csv




As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so:

head -n1 credential_report.csv




By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1”

In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|).  We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another.

As an example, we could substitute the comma for an asterisk using the following command:

head -n1 credential_report.csv | tr "," "*"




Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed:

head -n1 credential_report.csv | tr "," "\n"




There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines.

When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is:

head -n1 credential_report.csv | cut -d"," -f1-3,8




As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option.
Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head.

cat credential_report.csv | cut -d"," -f1-3,8




Let’s refine our output further by including only the “user” and “mfa_active” fields:

cat credential_report.csv | cut -d"," -f1,8




Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”.

cat credential_report.csv | cut -d"," -f1,8 | grep "FALSE"




Notice that by default, grep is case-sensitive. For example, we will not get any results if we use:

cat credential_report.csv | cut -d"," -f1,8 | grep "false"




That said, we can override this with the “-i” option, as shown:

cat credential_report.csv | cut -d"," -f1,8 | grep -i "false"




Next, let’s take another look at the list of all of our users again:

cat credential_report.csv | cut -d"," -f1,8




How could we remove the root_account from the result set? We could use the “-v” option with grep:

cat credential_report.csv | cut -d"," -f1,8 | grep -v "&lt;root_account&gt;"




Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities?

First, we need to identify the field numbers to cut:

head -n1 credential_report.csv | tr "," "\n"




Ok, it looks like we want fields one and three. Use cut to extract them.

cat credential_report.csv | cut -d"," -f1,3




Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines.

By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.”

In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest.

So, use:

cat credential_report.csv | cut -d"," -f1,3 | tail +2




Next, filter out the root account using grep -v

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;"




Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script.

Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2




We could reverse the sort order by passing in the “-r” option:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2 -r




If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc.  By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option.

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | wc -l




And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output.

For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics?

First, let’s revisit the prior analysis we performed on MFA:

cat credential_report.csv | cut -d"," -f1,8




Good. Now remove the header line and the root account as before:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;"




Now, lets chop off the user names:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2




And then sort it:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort




Now we can pipe it into uniq as shown:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq




Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option.

Let’s try that:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq -c




Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | uniq -c




Wrap Up

That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run

man wc




If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video.

If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.”

Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed.

Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel.

Take care.
">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc">
<meta name="twitter:description" content="5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc



Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum.

Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.”

The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors.

Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands.

The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal.

To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html

I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown:

wget https://headintheclouds.site/extras/ep6/credential_report.csv


Let’s take a look at the file:

cat credential_report.csv




As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so:

head -n1 credential_report.csv




By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1”

In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|).  We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another.

As an example, we could substitute the comma for an asterisk using the following command:

head -n1 credential_report.csv | tr "," "*"




Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed:

head -n1 credential_report.csv | tr "," "\n"




There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines.

When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is:

head -n1 credential_report.csv | cut -d"," -f1-3,8




As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option.
Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head.

cat credential_report.csv | cut -d"," -f1-3,8




Let’s refine our output further by including only the “user” and “mfa_active” fields:

cat credential_report.csv | cut -d"," -f1,8




Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”.

cat credential_report.csv | cut -d"," -f1,8 | grep "FALSE"




Notice that by default, grep is case-sensitive. For example, we will not get any results if we use:

cat credential_report.csv | cut -d"," -f1,8 | grep "false"




That said, we can override this with the “-i” option, as shown:

cat credential_report.csv | cut -d"," -f1,8 | grep -i "false"




Next, let’s take another look at the list of all of our users again:

cat credential_report.csv | cut -d"," -f1,8




How could we remove the root_account from the result set? We could use the “-v” option with grep:

cat credential_report.csv | cut -d"," -f1,8 | grep -v "&lt;root_account&gt;"




Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities?

First, we need to identify the field numbers to cut:

head -n1 credential_report.csv | tr "," "\n"




Ok, it looks like we want fields one and three. Use cut to extract them.

cat credential_report.csv | cut -d"," -f1,3




Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines.

By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.”

In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest.

So, use:

cat credential_report.csv | cut -d"," -f1,3 | tail +2




Next, filter out the root account using grep -v

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;"




Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script.

Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2




We could reverse the sort order by passing in the “-r” option:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2 -r




If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc.  By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option.

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | wc -l




And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output.

For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics?

First, let’s revisit the prior analysis we performed on MFA:

cat credential_report.csv | cut -d"," -f1,8




Good. Now remove the header line and the root account as before:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;"




Now, lets chop off the user names:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2




And then sort it:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort




Now we can pipe it into uniq as shown:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq




Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option.

Let’s try that:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq -c




Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | uniq -c




Wrap Up

That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run

man wc




If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video.

If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.”

Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed.

Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel.

Take care.
">
<meta name="twitter:site" content="@kennethghartman">
<meta name="twitter:creator" content="@kennethghartman">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="/images/default-thumb.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc">
<meta property="og:description" content="5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc



Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum.

Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.”

The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors.

Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands.

The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal.

To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html

I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown:

wget https://headintheclouds.site/extras/ep6/credential_report.csv


Let’s take a look at the file:

cat credential_report.csv




As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so:

head -n1 credential_report.csv




By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1”

In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|).  We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another.

As an example, we could substitute the comma for an asterisk using the following command:

head -n1 credential_report.csv | tr "," "*"




Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed:

head -n1 credential_report.csv | tr "," "\n"




There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines.

When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is:

head -n1 credential_report.csv | cut -d"," -f1-3,8




As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option.
Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head.

cat credential_report.csv | cut -d"," -f1-3,8




Let’s refine our output further by including only the “user” and “mfa_active” fields:

cat credential_report.csv | cut -d"," -f1,8




Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”.

cat credential_report.csv | cut -d"," -f1,8 | grep "FALSE"




Notice that by default, grep is case-sensitive. For example, we will not get any results if we use:

cat credential_report.csv | cut -d"," -f1,8 | grep "false"




That said, we can override this with the “-i” option, as shown:

cat credential_report.csv | cut -d"," -f1,8 | grep -i "false"




Next, let’s take another look at the list of all of our users again:

cat credential_report.csv | cut -d"," -f1,8




How could we remove the root_account from the result set? We could use the “-v” option with grep:

cat credential_report.csv | cut -d"," -f1,8 | grep -v "&lt;root_account&gt;"




Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities?

First, we need to identify the field numbers to cut:

head -n1 credential_report.csv | tr "," "\n"




Ok, it looks like we want fields one and three. Use cut to extract them.

cat credential_report.csv | cut -d"," -f1,3




Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines.

By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.”

In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest.

So, use:

cat credential_report.csv | cut -d"," -f1,3 | tail +2




Next, filter out the root account using grep -v

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;"




Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script.

Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2




We could reverse the sort order by passing in the “-r” option:

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2 -r




If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc.  By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option.

cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | wc -l




And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output.

For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics?

First, let’s revisit the prior analysis we performed on MFA:

cat credential_report.csv | cut -d"," -f1,8




Good. Now remove the header line and the root account as before:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;"




Now, lets chop off the user names:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2




And then sort it:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort




Now we can pipe it into uniq as shown:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq




Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option.

Let’s try that:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq -c




Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command:

cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | uniq -c




Wrap Up

That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run

man wc




If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video.

If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.”

Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed.

Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel.

Take care.
">
<meta property="og:url" content="/episodes/episode06/">
<meta property="og:site_name" content="Head in the Clouds">

<meta property="og:image" content="/images/default-thumb.png">






<link rel="canonical" href="/episodes/episode06/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Head in the Clouds Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">


<meta http-equiv="cleartype" content="on">


<!-- Modernizr -->
<script src="/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/assets/css/academicons/css/academicons.css"/>
<!-- Icons -->
<!-- 16x16 -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!--Jekyll-seo plugin-->
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc | Head in the Clouds</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum. Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.” The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors. Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands. The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal. To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown: wget https://headintheclouds.site/extras/ep6/credential_report.csv Let’s take a look at the file: cat credential_report.csv As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so: head -n1 credential_report.csv By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1” In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|). We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another. As an example, we could substitute the comma for an asterisk using the following command: head -n1 credential_report.csv | tr &quot;,&quot; &quot;*&quot; Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\n&quot; There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines. When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is: head -n1 credential_report.csv | cut -d&quot;,&quot; -f1-3,8 As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option. Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head. cat credential_report.csv | cut -d&quot;,&quot; -f1-3,8 Let’s refine our output further by including only the “user” and “mfa_active” fields: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”. cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;FALSE&quot; Notice that by default, grep is case-sensitive. For example, we will not get any results if we use: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;false&quot; That said, we can override this with the “-i” option, as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -i &quot;false&quot; Next, let’s take another look at the list of all of our users again: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 How could we remove the root_account from the result set? We could use the “-v” option with grep: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -v &quot;&lt;root_account&gt;&quot; Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities? First, we need to identify the field numbers to cut: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\n&quot; Ok, it looks like we want fields one and three. Use cut to extract them. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines. By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.” In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest. So, use: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 Next, filter out the root account using grep -v cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script. Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 We could reverse the sort order by passing in the “-r” option: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 -r If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc. By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | wc -l And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output. For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics? First, let’s revisit the prior analysis we performed on MFA: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Good. Now remove the header line and the root account as before: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Now, lets chop off the user names: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 And then sort it: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort Now we can pipe it into uniq as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option. Let’s try that: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq -c Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | uniq -c Wrap Up That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run man wc If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video. If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.” Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed. Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel. Take care." />
<meta property="og:description" content="5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum. Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.” The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors. Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands. The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal. To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown: wget https://headintheclouds.site/extras/ep6/credential_report.csv Let’s take a look at the file: cat credential_report.csv As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so: head -n1 credential_report.csv By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1” In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|). We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another. As an example, we could substitute the comma for an asterisk using the following command: head -n1 credential_report.csv | tr &quot;,&quot; &quot;*&quot; Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\n&quot; There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines. When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is: head -n1 credential_report.csv | cut -d&quot;,&quot; -f1-3,8 As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option. Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head. cat credential_report.csv | cut -d&quot;,&quot; -f1-3,8 Let’s refine our output further by including only the “user” and “mfa_active” fields: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”. cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;FALSE&quot; Notice that by default, grep is case-sensitive. For example, we will not get any results if we use: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;false&quot; That said, we can override this with the “-i” option, as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -i &quot;false&quot; Next, let’s take another look at the list of all of our users again: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 How could we remove the root_account from the result set? We could use the “-v” option with grep: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -v &quot;&lt;root_account&gt;&quot; Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities? First, we need to identify the field numbers to cut: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\n&quot; Ok, it looks like we want fields one and three. Use cut to extract them. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines. By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.” In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest. So, use: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 Next, filter out the root account using grep -v cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script. Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 We could reverse the sort order by passing in the “-r” option: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 -r If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc. By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | wc -l And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output. For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics? First, let’s revisit the prior analysis we performed on MFA: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Good. Now remove the header line and the root account as before: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Now, lets chop off the user names: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 And then sort it: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort Now we can pipe it into uniq as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option. Let’s try that: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq -c Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | uniq -c Wrap Up That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run man wc If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video. If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.” Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed. Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel. Take care." />
<link rel="canonical" href="http://localhost:4000/episodes/episode06/" />
<meta property="og:url" content="http://localhost:4000/episodes/episode06/" />
<meta property="og:site_name" content="Head in the Clouds" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-05-24T15:17:05-03:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-05-24T14:59:39-03:00","datePublished":"2022-05-24T15:17:05-03:00","description":"5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum. Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.” The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors. Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands. The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal. To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown: wget https://headintheclouds.site/extras/ep6/credential_report.csv Let’s take a look at the file: cat credential_report.csv As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the head command, like so: head -n1 credential_report.csv By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1” In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (|). We will use this technique to illustrate our next command, tr. The tr command allows us to substitute one character for another. As an example, we could substitute the comma for an asterisk using the following command: head -n1 credential_report.csv | tr &quot;,&quot; &quot;*&quot; Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\\n&quot; There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the cut command shines. When using cut, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is: head -n1 credential_report.csv | cut -d&quot;,&quot; -f1-3,8 As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option. Now, that we have selected the fields that we are interested in, we can look at all rows by using the cat command in place of head. cat credential_report.csv | cut -d&quot;,&quot; -f1-3,8 Let’s refine our output further by including only the “user” and “mfa_active” fields: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”. cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;FALSE&quot; Notice that by default, grep is case-sensitive. For example, we will not get any results if we use: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep &quot;false&quot; That said, we can override this with the “-i” option, as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -i &quot;false&quot; Next, let’s take another look at the list of all of our users again: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 How could we remove the root_account from the result set? We could use the “-v” option with grep: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | grep -v &quot;&lt;root_account&gt;&quot; Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities? First, we need to identify the field numbers to cut: head -n1 credential_report.csv | tr &quot;,&quot; &quot;\\n&quot; Ok, it looks like we want fields one and three. Use cut to extract them. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the tail command. Normally, tail works the opposite of the head command. While head displays the top 10 lines of a file, by default, tail displays the last 10 lines. By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.” In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest. So, use: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 Next, filter out the root account using grep -v cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Note: We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script. Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 We could reverse the sort order by passing in the “-r” option: cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | sort -k2 -r If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, wc. By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option. cat credential_report.csv | cut -d&quot;,&quot; -f1,3 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | wc -l And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output. For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics? First, let’s revisit the prior analysis we performed on MFA: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 Good. Now remove the header line and the root account as before: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; Now, lets chop off the user names: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 And then sort it: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort Now we can pipe it into uniq as shown: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option. Let’s try that: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | sort | uniq -c Note: the uniq utility assumes that the input is sorted. To illustrate what I mean, remove the sort command: cat credential_report.csv | cut -d&quot;,&quot; -f1,8 | tail +2 | grep -v &quot;&lt;root_account&gt;&quot; | cut -d&quot;,&quot; -f2 | uniq -c Wrap Up That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by wc, just run man wc If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video. If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.” Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed. Meanwhile, be sure to check out the other great videos on the SANS Cloud Security YouTube Channel. Take care.","headline":"Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/episodes/episode06/"},"url":"http://localhost:4000/episodes/episode06/"}</script>
<!-- End Jekyll SEO tag -->


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-K6EX94SG73"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-K6EX94SG73');
</script>


</head>

<body class="page">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		
		<a href="/">Head in the Clouds</a>
		
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="/" >Home</a></li>
				
				    
				    <li><a href="/episodes/" >All Episodes</a></li>
				
				    
				    <li><a href="https://www.sans.org/cyber-security-courses/?focus-area=cloud-security" target="_blank">SANS CyberSec Courses & Certs</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->




<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="https://schema.org/Person">


	<img src="/images/Cloud_Ace_Final.png" class="bio-photo" alt="Head in the Clouds bio photo">


  <h3 itemprop="name">Head in the Clouds</h3>
  <p>with Kenneth G. Hartman<p>Certified SANS Instructor</p>
  <a href="mailto:kgh@kennethghartman.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  <a href="https://twitter.com/kennethghartman" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  
  
  
  
  
  <a href="https://github.com/Resistor52" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> GitHub</a>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="page">
    <h1>Episode 6 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc</h1>
    <div class="article-wrap">
      <p>5 - Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc</p>

<div class="video-container"><iframe width="560" height="315" src="https://www.youtube.com/embed/_RroGGMz49I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>

<p>Welcome to Episode 6 of the “Head in the Clouds” Video Series. I am Ken Hartman, a SANS Certified Instructor and content creator for the SANS Cloud Security Curriculum.</p>

<p>Today’s episode is titled: “Slice and Dice Data using grep, head, tail, cut, sort, tr, uniq and wc.”</p>

<p>The purpose of HITC is to teach foundational cloud skills and security knowledge that will help others thrive in the cloud. The content ideas come from my personal observation of skills that I see some students lacking when they show up to a SANS Cloud Security course. Other ideas are passed on from fellow SANS instructors.</p>

<p>Today’s topic builds upon our last episode which was titled “Tips for success with Command Line Interfaces using BASH.” While the last episode provided useful skills for navigating the BASH shell when using a CLI, this episode is focused on manipulating the data that is returned by such commands.</p>

<p>The commands that we will be covering are grep, head, tail, cut, sort, tr, uniq and wc. These utilities are commands that I use almost every day and I highly recommend that you add them to your arsenal.</p>

<p>To start, we must have some data to work with. And since we are building cloud security skills, let’s use some data from the cloud. Amazon Web Services has a report that we can download that contains a list of all IAM users in each AWS Account. This is called the “Credentials Report” and it is a great way to audit user accounts. You can learn more about the credential report at: <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html</a></p>

<p>I have created a sample credential report that you can use to follow along as we explore the commands that we will be covering. Once you have opened a Linux terminal, you can download the file using wget as shown:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://headintheclouds.site/extras/ep6/credential_report.csv
</code></pre></div></div>

<p>Let’s take a look at the file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv
</code></pre></div></div>

<p><img src="/images/ep6/cred_report.png" alt="Image of the Sample Credential Report" /></p>

<p>As we can see, the first line has the headings for each column in the comma separated value (CSV) file. To get just the first line displayed to stdout, we can use the <strong>head</strong> command, like so:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n1 credential_report.csv
</code></pre></div></div>

<p><img src="/images/ep6/cred_report_line1.png" alt="Image of the first line of the credentials report" /></p>

<p>By default, the head command will print the first ten lines of a file, unless we override that with the “-n” option. In this case, we told head to print just the first line using “-n1”</p>

<p>In Linux, it is a common practice to pipe the output of one command into another. To do that we use the pipe symbol, which is the vertical bar (<code class="language-plaintext highlighter-rouge">|</code>).  We will use this technique to illustrate our next command, <strong>tr</strong>. The <strong>tr</strong> command allows us to substitute one character for another.</p>

<p>As an example, we could substitute the comma for an asterisk using the following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n1 credential_report.csv | tr "," "*"
</code></pre></div></div>

<p><img src="/images/ep6/tr1.png" alt="Image illustrating the tr utility" /></p>

<p>Note that we can even use control characters such as tabs or line feeds. Let’s rerun the command but substitute in a line feed:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n1 credential_report.csv | tr "," "\n"
</code></pre></div></div>

<p><img src="/images/ep6/tr2.png" alt="Image illustrating the tr utility with line feeds" /></p>

<p>There, that is much easier to read. Now, what if we only wanted to see the “user”, “arn,” user_creation_time,” and “mfa_active” fields? This is where the <strong>cut</strong> command shines.</p>

<p>When using <strong>cut</strong>, we need to tell it what character to use as a delimiter and the field numbers to return to standard output. Thus, the command that we want to use is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n1 credential_report.csv | cut -d"," -f1-3,8
</code></pre></div></div>

<p><img src="/images/ep6/cut1.png" alt="Image illustrating the cut utility" /></p>

<p>As you can see, we pass in the delimiter using the “-d” option, and the fields to use using the “-f” option.
Now, that we have selected the fields that we are interested in, we can look at all rows by using the <strong>cat</strong> command in place of <strong>head</strong>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1-3,8
</code></pre></div></div>

<p><img src="/images/ep6/cut2.png" alt="Image illustrating the cut utility with cat" /></p>

<p>Let’s refine our output further by including only the “user” and “mfa_active” fields:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8
</code></pre></div></div>

<p><img src="/images/ep6/cut3.png" alt="Another image illustrating the cut utility with cat" /></p>

<p>Perhaps we want to generate a list of users who did not have MFA on their user accounts. In that case we can use “grep” to return just the rows where the mfa_active column contains “FALSE”.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | grep "FALSE"
</code></pre></div></div>

<p><img src="/images/ep6/grep1.png" alt="Image illustrating the grep utility" /></p>

<p>Notice that by default, grep is case-sensitive. For example, we will not get any results if we use:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | grep "false"
</code></pre></div></div>

<p><img src="/images/ep6/grep2.png" alt="Image illustrating the grep case sensitivity" /></p>

<p>That said, we can override this with the “-i” option, as shown:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | grep -i "false"
</code></pre></div></div>

<p><img src="/images/ep6/grep3.png" alt="Image illustrating the grep case insensitivity" /></p>

<p>Next, let’s take another look at the list of all of our users again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8
</code></pre></div></div>

<p><img src="/images/ep6/users.png" alt="List of users and MFA status" /></p>

<p>How could we remove the root_account from the result set? We could use the “-v” option with grep:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | grep -v "&lt;root_account&gt;"
</code></pre></div></div>

<p><img src="/images/ep6/users_no_root.png" alt="List of users without root" /></p>

<p>Perhaps we want to know which user (besides root) was the first to be created? How would we determine that using our command line utilities?</p>

<p>First, we need to identify the field numbers to cut:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n1 credential_report.csv | tr "," "\n"
</code></pre></div></div>

<p><img src="/images/ep6/cred_report_fields.png" alt="List of fields in the credentials report" /></p>

<p>Ok, it looks like we want fields one and three. Use cut to extract them.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3
</code></pre></div></div>

<p><img src="/images/ep6/user_create_times.png" alt="List of user creation times" /></p>

<p>Next, let’s drop the first line that contains the headings of each column. To do that, we will use a special feature of the <strong>tail</strong> command. Normally, <strong>tail</strong> works the opposite of the <strong>head</strong> command. While <strong>head</strong> displays the top 10 lines of a file, by default, <strong>tail</strong> displays the last 10 lines.</p>

<p>By the way, tail has a great option for monitoring a log file as it is being written. This is the “-f” option. Remember that as “f as in follow.”</p>

<p>In our case, we want all of the lines except the first, so we will use “+2” as our optional argument to the command. This tells tail to start at line 2 and output that line and all of the rest.</p>

<p>So, use:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3 | tail +2
</code></pre></div></div>

<p><img src="/images/ep6/user_create_times2.png" alt="List of user creation times without header" /></p>

<p>Next, filter out the root account using <strong>grep -v</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;"
</code></pre></div></div>

<p><img src="/images/ep6/user_create_times3.png" alt="List of user creation times without header and root" /></p>

<p><strong>Note:</strong> We could have just had the tail command start at line 3, which would also have excluded the line with the root account, but that makes an assumption that the root account will always be in the second line. That type of an assumption may be fine for an ad hoc analysis, but not something you would want to do when developing a script.</p>

<p>Now to perform the sort. Notice that the data that we are interested in sorting is in the second column. We need to tell sort to use the second column. We do that with the “-k” option, as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2
</code></pre></div></div>

<p><img src="/images/ep6/sorted_users.png" alt="List of users sorted by creation time" /></p>

<p>We could reverse the sort order by passing in the “-r” option:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | sort -k2 -r
</code></pre></div></div>

<p><img src="/images/ep6/sorted_users2.png" alt="List of users reverse sorted by creation time" /></p>

<p>If you wonder how many IAM users are listed in the Credential Report, we can use the word count utility, <strong>wc</strong>.  By default, wc prints the number of lines, words, and bytes for a file. To get just the line count, use the “-l” option.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,3 | tail +2 | grep -v "&lt;root_account&gt;" | wc -l
</code></pre></div></div>

<p><img src="/images/ep6/user_count.png" alt="Count of IAM users" /></p>

<p>And based on the results of this command, we can see that we have six IAM users, because the root account does not count as an IAM user. Sure we could have hand-counted these, but this utility is great when there are hundreds of lines in the output.</p>

<p>For another scenario, let’s say we want to determine how many users have MFA configured and how many do not. How could we generate these metrics?</p>

<p>First, let’s revisit the prior analysis we performed on MFA:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8
</code></pre></div></div>

<p><img src="/images/ep6/users.png" alt="List of users and MFA status" /></p>

<p>Good. Now remove the header line and the root account as before:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;"
</code></pre></div></div>

<p><img src="/images/ep6/users2.png" alt="List of users and MFA status, no header or root" /></p>

<p>Now, lets chop off the user names:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2
</code></pre></div></div>

<p><img src="/images/ep6/mfa.png" alt="List of MFA status" /></p>

<p>And then sort it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort
</code></pre></div></div>

<p><img src="/images/ep6/mfa2.png" alt="Sorted list of MFA status" /></p>

<p>Now we can pipe it into <strong>uniq</strong> as shown:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq
</code></pre></div></div>

<p><img src="/images/ep6/mfa3.png" alt="List of unique MFA status" /></p>

<p>Well, that didn’t give us the counts we were expecting, did it? Turns out, we were missing the “-c” option.</p>

<p>Let’s try that:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | sort | uniq -c
</code></pre></div></div>

<p><img src="/images/ep6/mfa4.png" alt="Count by unique MFA status" /></p>

<p><strong>Note:</strong> the <strong>uniq</strong> utility assumes that the input is sorted. To illustrate what I mean, remove the sort command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat credential_report.csv | cut -d"," -f1,8 | tail +2 | grep -v "&lt;root_account&gt;" | cut -d"," -f2 | uniq -c
</code></pre></div></div>

<p><img src="/images/ep6/mfa5.png" alt="Erroneous Count by unique MFA status" /></p>

<h2 id="wrap-up">Wrap Up</h2>

<p>That’s it! Now you know some very useful command line utilities to slice and dice data. Each of these utilities have many options that we have not explored. Remember that you can always use the man page to get the details on how to use the command, along with the list of supported options. For example to see the options supported by <strong>wc</strong>, just run</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>man wc
</code></pre></div></div>

<p><img src="/images/ep6/man_wc.png" alt="Man page of wc utility" /></p>

<p>If you have thoughts or comments on today’s episode, feel free to chime in on the comments for this YouTube video.</p>

<p>If you appreciate this video and want to see more like it, be sure to give it a “thumbs up.”</p>

<p>Stay tuned for another installment of “Head in the Clouds” as announcements of new episodes are made on the SANS Cloud Security Twitter feed.</p>

<p>Meanwhile, be sure to check out the other great videos on the <a href="https://www.youtube.com/c/SANSCloudSecurity">SANS Cloud Security YouTube Channel</a>.</p>

<p>Take care.</p>

      
        <hr />
        <div class="social-share">
  <!--<h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=/episodes/episode06/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=/episodes/episode06/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=/episodes/episode06/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->

      
    </div><!-- /.article-wrap -->
    
  </article>
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    

<span>&copy; 2022 Head in the Clouds.<br /></span>


  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-25220220-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>




</body>
</html>
